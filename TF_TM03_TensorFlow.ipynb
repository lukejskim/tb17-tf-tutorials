{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S03. 텐서플로 이해"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서플로 기본 메카니즘\n",
    "> 텐서플로우의 기본적인 구성을 익힙니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const:0\", shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "# tf.constant: 말 그대로 상수입니다.\n",
    "hello = tf.constant('Hello, TensorFlow!')\n",
    "print(hello)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Add:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant(10)\n",
    "b = tf.constant(32)\n",
    "c = tf.add(a, b)  # a + b 로도 쓸 수 있음\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello, TensorFlow!'\n",
      "[10, 32, 42]\n"
     ]
    }
   ],
   "source": [
    "# 위에서 변수와 수식들을 정의했지만, 실행이 정의한 시점에서 실행되는 것은 아닙니다.\n",
    "# 다음처럼 Session 객제와 run 메소드를 사용할 때 계산이 됩니다.\n",
    "# 따라서 모델을 구성하는 것과, 실행하는 것을 분리하여 프로그램을 깔끔하게 작성할 수 있습니다.\n",
    "# 그래프를 실행할 세션을 구성합니다.\n",
    "sess = tf.Session()\n",
    "# sess.run: 설정한 텐서 그래프(변수나 수식 등등)를 실행합니다.\n",
    "print(sess.run(hello))\n",
    "print(sess.run([a, b, c]))\n",
    "\n",
    "# 세션을 닫습니다.\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텐서플로 변수, Variable\n",
    "> 플레이스홀더와 변수의 이해"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder:0\", shape=(?, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# tf.placeholder: 계산을 실행할 때 입력값을 받는 변수로 사용합니다.\n",
    "# None 은 크기가 정해지지 않았음을 의미합니다.\n",
    "X = tf.placeholder(tf.float32, [None, 3])\n",
    "print(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X 플레이스홀더에 넣을 값 입니다.\n",
    "# 플레이스홀더에서 설정한 것 처럼, 두번째 차원의 요소의 갯수는 3개 입니다.\n",
    "x_data = [[1, 2, 3], [4, 5, 6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tf.Variable: 그래프를 계산하면서 최적화 할 변수들입니다. 이 값이 바로 신경망을 좌우하는 값들입니다.\n",
    "# tf.random_normal: 각 변수들의 초기값을 정규분포 랜덤 값으로 초기화합니다.\n",
    "W = tf.Variable(tf.random_normal([3, 2]))\n",
    "b = tf.Variable(tf.random_normal([2, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 입력값과 변수들을 계산할 수식을 작성합니다.\n",
    "# tf.matmul 처럼 mat* 로 되어 있는 함수로 행렬 계산을 수행합니다.\n",
    "expr = tf.matmul(X, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "# 위에서 설정한 Variable 들의 값들을 초기화 하기 위해\n",
    "# 처음에 tf.global_variables_initializer 를 한 번 실행해야 합니다.\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3], [4, 5, 6]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.24654019, -0.12626654],\n",
       "       [-0.27012882, -0.62068117],\n",
       "       [-0.75152344,  0.03703217]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.64885032],\n",
       "       [ 0.73889661]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -4.69021845,  -1.90538263],\n",
       "       [-10.10704899,  -2.6473825 ]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# expr 수식에는 X 라는 입력값이 필요합니다.\n",
    "# 따라서 expr 실행시에는 이 변수에 대한 실제 입력값을 다음처럼 넣어줘야합니다.\n",
    "sess.run(expr, feed_dict={X: x_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 선형회귀모델, Lineare Regression\n",
    ">  X 와 Y 의 상관관계를 분석하는 기초적인 선형 회귀 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_data = [1, 2, 3]\n",
    "y_data = [1, 2, 3]\n",
    "\n",
    "W = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
    "b = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'X:0' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'Y:0' shape=<unknown> dtype=float32>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# name: 나중에 텐서보드등으로 값의 변화를 추적하거나 살펴보기 쉽게 하기 위해 이름을 붙여줍니다.\n",
    "X = tf.placeholder(tf.float32, name=\"X\")\n",
    "Y = tf.placeholder(tf.float32, name=\"Y\")\n",
    "X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X 와 Y 의 상관 관계를 분석하기 위한 가설 수식을 작성합니다.\n",
    "# y = W * x + b\n",
    "# W 와 X 가 행렬이 아니므로 tf.matmul 이 아니라 기본 곱셈 기호를 사용했습니다.\n",
    "hypothesis = W * X + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 손실 함수를 작성합니다.\n",
    "# mean(h - Y)^2 : 예측값과 실제값의 거리를 비용(손실) 함수로 정합니다.\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 텐서플로우에 기본적으로 포함되어 있는 함수를 이용해 경사 하강법 최적화를 수행합니다.\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 비용을 최소화 하는 것이 최종 목표\n",
    "train_op = optimizer.minimize(cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.141045 [ 0.70911765] [ 0.62853682]\n",
      "1 0.058596 [ 0.72919309] [ 0.61918241]\n",
      "2 0.0549078 [ 0.73427325] [ 0.60366869]\n",
      "3 0.0522888 [ 0.74081743] [ 0.58922565]\n",
      "4 0.0498049 [ 0.74703091] [ 0.57505357]\n",
      "5 0.0474392 [ 0.75311399] [ 0.56123048]\n",
      "6 0.0451858 [ 0.75904876] [ 0.54773879]\n",
      "7 0.0430394 [ 0.76484102] [ 0.53457153]\n",
      "8 0.040995 [ 0.77049416] [ 0.52172083]\n",
      "9 0.0390477 [ 0.77601129] [ 0.509179]\n",
      "10 0.0371929 [ 0.78139579] [ 0.49693868]\n",
      "11 0.0354263 [ 0.7866509] [ 0.48499262]\n",
      "12 0.0337434 [ 0.79177964] [ 0.47333375]\n",
      "13 0.0321406 [ 0.79678512] [ 0.46195513]\n",
      "14 0.0306139 [ 0.80167031] [ 0.45085007]\n",
      "15 0.0291597 [ 0.80643803] [ 0.44001195]\n",
      "16 0.0277746 [ 0.81109107] [ 0.42943436]\n",
      "17 0.0264553 [ 0.81563234] [ 0.41911104]\n",
      "18 0.0251987 [ 0.82006443] [ 0.40903589]\n",
      "19 0.0240017 [ 0.82438993] [ 0.39920294]\n",
      "20 0.0228616 [ 0.82861155] [ 0.38960639]\n",
      "21 0.0217757 [ 0.83273154] [ 0.3802405]\n",
      "22 0.0207413 [ 0.83675253] [ 0.37109977]\n",
      "23 0.0197561 [ 0.8406769] [ 0.3621788]\n",
      "24 0.0188176 [ 0.84450692] [ 0.35347226]\n",
      "25 0.0179238 [ 0.84824491] [ 0.34497505]\n",
      "26 0.0170724 [ 0.85189301] [ 0.33668208]\n",
      "27 0.0162614 [ 0.85545337] [ 0.32858846]\n",
      "28 0.015489 [ 0.8589282] [ 0.32068941]\n",
      "29 0.0147533 [ 0.86231941] [ 0.31298023]\n",
      "30 0.0140525 [ 0.8656292] [ 0.30545643]\n",
      "31 0.013385 [ 0.86885941] [ 0.29811347]\n",
      "32 0.0127492 [ 0.8720119] [ 0.29094699]\n",
      "33 0.0121436 [ 0.87508869] [ 0.28395283]\n",
      "34 0.0115668 [ 0.87809151] [ 0.27712682]\n",
      "35 0.0110173 [ 0.88102204] [ 0.27046484]\n",
      "36 0.010494 [ 0.88388216] [ 0.26396304]\n",
      "37 0.00999553 [ 0.88667357] [ 0.25761756]\n",
      "38 0.00952073 [ 0.88939786] [ 0.25142461]\n",
      "39 0.00906849 [ 0.8920567] [ 0.24538055]\n",
      "40 0.00863773 [ 0.89465153] [ 0.23948175]\n",
      "41 0.00822743 [ 0.89718407] [ 0.23372479]\n",
      "42 0.00783662 [ 0.8996557] [ 0.2281062]\n",
      "43 0.00746438 [ 0.9020679] [ 0.22262268]\n",
      "44 0.00710981 [ 0.90442216] [ 0.21727099]\n",
      "45 0.00677209 [ 0.90671974] [ 0.21204792]\n",
      "46 0.00645041 [ 0.90896213] [ 0.20695044]\n",
      "47 0.00614402 [ 0.91115063] [ 0.20197551]\n",
      "48 0.00585217 [ 0.91328651] [ 0.19712016]\n",
      "49 0.00557418 [ 0.91537106] [ 0.19238153]\n",
      "50 0.0053094 [ 0.91740543] [ 0.18775678]\n",
      "51 0.0050572 [ 0.91939098] [ 0.18324324]\n",
      "52 0.00481698 [ 0.92132878] [ 0.17883821]\n",
      "53 0.00458818 [ 0.92321998] [ 0.17453904]\n",
      "54 0.00437023 [ 0.9250657] [ 0.17034325]\n",
      "55 0.00416265 [ 0.92686713] [ 0.16624834]\n",
      "56 0.00396491 [ 0.92862511] [ 0.16225182]\n",
      "57 0.00377658 [ 0.93034101] [ 0.15835142]\n",
      "58 0.00359719 [ 0.93201548] [ 0.15454474]\n",
      "59 0.00342632 [ 0.93364978] [ 0.1508296]\n",
      "60 0.00326357 [ 0.93524486] [ 0.14720377]\n",
      "61 0.00310854 [ 0.93680149] [ 0.14366508]\n",
      "62 0.00296088 [ 0.9383207] [ 0.14021145]\n",
      "63 0.00282024 [ 0.93980348] [ 0.13684088]\n",
      "64 0.00268629 [ 0.94125056] [ 0.13355133]\n",
      "65 0.00255868 [ 0.94266284] [ 0.13034083]\n",
      "66 0.00243714 [ 0.94404119] [ 0.12720752]\n",
      "67 0.00232138 [ 0.94538641] [ 0.12414955]\n",
      "68 0.00221111 [ 0.94669926] [ 0.12116507]\n",
      "69 0.00210607 [ 0.94798058] [ 0.11825234]\n",
      "70 0.00200604 [ 0.94923115] [ 0.11540965]\n",
      "71 0.00191075 [ 0.95045155] [ 0.11263527]\n",
      "72 0.00181999 [ 0.95164263] [ 0.10992759]\n",
      "73 0.00173353 [ 0.9528051] [ 0.107285]\n",
      "74 0.00165119 [ 0.95393968] [ 0.10470596]\n",
      "75 0.00157276 [ 0.95504689] [ 0.10218889]\n",
      "76 0.00149805 [ 0.95612758] [ 0.09973236]\n",
      "77 0.00142689 [ 0.95718223] [ 0.09733486]\n",
      "78 0.00135911 [ 0.95821154] [ 0.09499501]\n",
      "79 0.00129455 [ 0.95921606] [ 0.09271138]\n",
      "80 0.00123306 [ 0.9601965] [ 0.09048268]\n",
      "81 0.00117449 [ 0.96115333] [ 0.08830754]\n",
      "82 0.0011187 [ 0.96208715] [ 0.0861847]\n",
      "83 0.00106557 [ 0.96299857] [ 0.08411288]\n",
      "84 0.00101495 [ 0.96388811] [ 0.08209088]\n",
      "85 0.000966742 [ 0.96475619] [ 0.08011746]\n",
      "86 0.00092082 [ 0.96560347] [ 0.0781915]\n",
      "87 0.000877077 [ 0.96643025] [ 0.0763118]\n",
      "88 0.000835414 [ 0.96723729] [ 0.07447734]\n",
      "89 0.000795732 [ 0.96802485] [ 0.07268695]\n",
      "90 0.000757933 [ 0.96879351] [ 0.07093962]\n",
      "91 0.000721934 [ 0.9695437] [ 0.06923429]\n",
      "92 0.00068764 [ 0.97027582] [ 0.06756994]\n",
      "93 0.000654977 [ 0.97099042] [ 0.06594563]\n",
      "94 0.000623866 [ 0.97168779] [ 0.06436034]\n",
      "95 0.000594233 [ 0.97236836] [ 0.06281315]\n",
      "96 0.000566005 [ 0.97303265] [ 0.06130318]\n",
      "97 0.000539122 [ 0.97368091] [ 0.05982948]\n",
      "98 0.000513514 [ 0.97431362] [ 0.05839121]\n",
      "99 0.000489122 [ 0.97493112] [ 0.05698753]\n",
      "\n",
      "=== Test ===\n",
      "X: 5, Y: [ 4.93164349]\n",
      "X: 2.5, Y: [ 2.49431539]\n"
     ]
    }
   ],
   "source": [
    "# 세션을 생성하고 초기화합니다.\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # 최적화를 100번 수행합니다.\n",
    "    for step in range(100):\n",
    "        # sess.run 을 통해 train_op 와 cost 그래프를 계산합니다.\n",
    "        # 이 때, 가설 수식에 넣어야 할 실제값을 feed_dict 을 통해 전달합니다.\n",
    "        _, cost_val = sess.run([train_op, cost], feed_dict={X: x_data, Y: y_data})\n",
    "\n",
    "        print(step, cost_val, sess.run(W), sess.run(b))\n",
    "\n",
    "    # 최적화가 완료된 모델에 테스트 값을 넣고 결과가 잘 나오는지 확인해봅니다.\n",
    "    print(\"\\n=== Test ===\")\n",
    "    print(\"X: 5, Y:\", sess.run(hypothesis, feed_dict={X: 5}))\n",
    "    print(\"X: 2.5, Y:\", sess.run(hypothesis, feed_dict={X: 2.5}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf1_basic.py \n",
    "<hr>\n",
    "``` python\n",
    "# 텐서플로우의 기본적인 구성을 익힙니다.\n",
    "import tensorflow as tf\n",
    "\n",
    "# tf.constant: 말 그대로 상수입니다.\n",
    "hello = tf.constant('Hello, TensorFlow!')\n",
    "print(hello)\n",
    "\n",
    "a = tf.constant(10)\n",
    "b = tf.constant(32)\n",
    "c = tf.add(a, b)  # a + b 로도 쓸 수 있음\n",
    "print(c)\n",
    "\n",
    "# 위에서 변수와 수식들을 정의했지만, 실행이 정의한 시점에서 실행되는 것은 아닙니다.\n",
    "# 다음처럼 Session 객제와 run 메소드를 사용할 때 계산이 됩니다.\n",
    "# 따라서 모델을 구성하는 것과, 실행하는 것을 분리하여 프로그램을 깔끔하게 작성할 수 있습니다.\n",
    "# 그래프를 실행할 세션을 구성합니다.\n",
    "sess = tf.Session()\n",
    "# sess.run: 설정한 텐서 그래프(변수나 수식 등등)를 실행합니다.\n",
    "print(sess.run(hello))\n",
    "print(sess.run([a, b, c]))\n",
    "\n",
    "# 세션을 닫습니다.\n",
    "sess.close()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf2_variable.py\n",
    "<hr>\n",
    "``` python\n",
    "# 플레이스홀더와 변수의 개념을 익혀봅니다\n",
    "import tensorflow as tf\n",
    "\n",
    "# tf.placeholder: 계산을 실행할 때 입력값을 받는 변수로 사용합니다.\n",
    "# None 은 크기가 정해지지 않았음을 의미합니다.\n",
    "X = tf.placeholder(tf.float32, [None, 3])\n",
    "print(X)\n",
    "\n",
    "# X 플레이스홀더에 넣을 값 입니다.\n",
    "# 플레이스홀더에서 설정한 것 처럼, 두번째 차원의 요소의 갯수는 3개 입니다.\n",
    "x_data = [[1, 2, 3], [4, 5, 6]]\n",
    "\n",
    "# tf.Variable: 그래프를 계산하면서 최적화 할 변수들입니다. 이 값이 바로 신경망을 좌우하는 값들입니다.\n",
    "# tf.random_normal: 각 변수들의 초기값을 정규분포 랜덤 값으로 초기화합니다.\n",
    "W = tf.Variable(tf.random_normal([3, 2]))\n",
    "b = tf.Variable(tf.random_normal([2, 1]))\n",
    "\n",
    "# 입력값과 변수들을 계산할 수식을 작성합니다.\n",
    "# tf.matmul 처럼 mat* 로 되어 있는 함수로 행렬 계산을 수행합니다.\n",
    "expr = tf.matmul(X, W) + b\n",
    "\n",
    "sess = tf.Session()\n",
    "# 위에서 설정한 Variable 들의 값들을 초기화 하기 위해\n",
    "# 처음에 tf.global_variables_initializer 를 한 번 실행해야 합니다.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "print(\"=== x_data ===\")\n",
    "print(x_data)\n",
    "print(\"=== W ===\")\n",
    "print(sess.run(W))\n",
    "print(\"=== b ===\")\n",
    "print(sess.run(b))\n",
    "print(\"=== expr ===\")\n",
    "# expr 수식에는 X 라는 입력값이 필요합니다.\n",
    "# 따라서 expr 실행시에는 이 변수에 대한 실제 입력값을 다음처럼 넣어줘야합니다.\n",
    "print(sess.run(expr, feed_dict={X: x_data}))\n",
    "\n",
    "sess.close()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf3_linear_regression.py\n",
    "<hr>\n",
    "``` python\n",
    "# X 와 Y 의 상관관계를 분석하는 기초적인 선형 회귀 모델을 만들고 실행해봅니다.\n",
    "import tensorflow as tf\n",
    "\n",
    "x_data = [1, 2, 3]\n",
    "y_data = [1, 2, 3]\n",
    "\n",
    "W = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
    "b = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
    "\n",
    "# name: 나중에 텐서보드등으로 값의 변화를 추적하거나 살펴보기 쉽게 하기 위해 이름을 붙여줍니다.\n",
    "X = tf.placeholder(tf.float32, name=\"X\")\n",
    "Y = tf.placeholder(tf.float32, name=\"Y\")\n",
    "print(X)\n",
    "print(Y)\n",
    "\n",
    "# X 와 Y 의 상관 관계를 분석하기 위한 가설 수식을 작성합니다.\n",
    "# y = W * x + b\n",
    "# W 와 X 가 행렬이 아니므로 tf.matmul 이 아니라 기본 곱셈 기호를 사용했습니다.\n",
    "hypothesis = W * X + b\n",
    "\n",
    "# 손실 함수를 작성합니다.\n",
    "# mean(h - Y)^2 : 예측값과 실제값의 거리를 비용(손실) 함수로 정합니다.\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "# 텐서플로우에 기본적으로 포함되어 있는 함수를 이용해 경사 하강법 최적화를 수행합니다.\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "# 비용을 최소화 하는 것이 최종 목표\n",
    "train_op = optimizer.minimize(cost)\n",
    "\n",
    "# 세션을 생성하고 초기화합니다.\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # 최적화를 100번 수행합니다.\n",
    "    for step in range(100):\n",
    "        # sess.run 을 통해 train_op 와 cost 그래프를 계산합니다.\n",
    "        # 이 때, 가설 수식에 넣어야 할 실제값을 feed_dict 을 통해 전달합니다.\n",
    "        _, cost_val = sess.run([train_op, cost], feed_dict={X: x_data, Y: y_data})\n",
    "\n",
    "        print(step, cost_val, sess.run(W), sess.run(b))\n",
    "\n",
    "    # 최적화가 완료된 모델에 테스트 값을 넣고 결과가 잘 나오는지 확인해봅니다.\n",
    "    print(\"\\n=== Test ===\")\n",
    "    print(\"X: 5, Y:\", sess.run(hypothesis, feed_dict={X: 5}))\n",
    "    print(\"X: 2.5, Y:\", sess.run(hypothesis, feed_dict={X: 2.5}))\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
