{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S09_GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAN.py\n",
    "> 대표적인 비지도(Unsupervised) 학습 방법인 GAN 구현\n",
    "- Generative Adversarial Network(GAN)\n",
    "- 2016년에 가장 관심을 많이 받았던 비감독(Unsupervised) 학습 방법 중 하나\n",
    "- https://arxiv.org/abs/1406.2661"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bigpycraft/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-6b1cf8cfcfe6>:7: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Users/bigpycraft/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Users/bigpycraft/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/bigpycraft/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/bigpycraft/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/bigpycraft/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "# 옵션 설정\n",
    "######\n",
    "total_epoch   = 100\n",
    "batch_size    = 100\n",
    "learning_rate = 0.0002\n",
    "\n",
    "# 신경망 레이어 구성 옵션\n",
    "n_hidden = 256\n",
    "n_input  = 28 * 28\n",
    "n_noise  = 128  # 생성기의 입력값으로 사용할 노이즈의 크기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "# 신경망 모델 구성\n",
    "######\n",
    "# GAN 도 Unsupervised 학습이므로 Autoencoder 처럼 Y 를 사용하지 않습니다.\n",
    "X = tf.placeholder(tf.float32, [None, n_input])\n",
    "# 노이즈 Z를 입력값으로 사용합니다.\n",
    "Z = tf.placeholder(tf.float32, [None, n_noise])\n",
    "\n",
    "# 생성기 신경망에 사용하는 변수들입니다.\n",
    "G_W1 = tf.Variable(tf.random_normal([n_noise, n_hidden], stddev=0.01))\n",
    "G_b1 = tf.Variable(tf.zeros([n_hidden]))\n",
    "G_W2 = tf.Variable(tf.random_normal([n_hidden, n_input], stddev=0.01))\n",
    "G_b2 = tf.Variable(tf.zeros([n_input]))\n",
    "\n",
    "# 판별기 신경망에 사용하는 변수들입니다.\n",
    "D_W1 = tf.Variable(tf.random_normal([n_input, n_hidden], stddev=0.01))\n",
    "D_b1 = tf.Variable(tf.zeros([n_hidden]))\n",
    "# 판별기의 최종 결과값은 얼마나 진짜와 가깝냐를 판단하는 한 개의 스칼라값입니다.\n",
    "D_W2 = tf.Variable(tf.random_normal([n_hidden, 1], stddev=0.01))\n",
    "D_b2 = tf.Variable(tf.zeros([1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성기(G) 신경망을 구성합니다.\n",
    "def generator(noise_z):\n",
    "    hidden = tf.nn.relu(\n",
    "                    tf.matmul(noise_z, G_W1) + G_b1)\n",
    "    output = tf.nn.sigmoid(\n",
    "                    tf.matmul(hidden, G_W2) + G_b2)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "# 판별기(D) 신경망을 구성합니다.\n",
    "def discriminator(inputs):\n",
    "    hidden = tf.nn.relu(\n",
    "                    tf.matmul(inputs, D_W1) + D_b1)\n",
    "    output = tf.nn.sigmoid(\n",
    "                    tf.matmul(hidden, D_W2) + D_b2)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "# 랜덤한 노이즈(Z)를 만듭니다.\n",
    "def get_noise(batch_size, n_noise):\n",
    "    return np.random.normal(size=(batch_size, n_noise))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 노이즈를 이용해 랜덤한 이미지를 생성합니다.\n",
    "G = generator(Z)\n",
    "# 노이즈를 이용해 생성한 이미지가 진짜 이미지인지 판별한 값을 구합니다.\n",
    "D_gene = discriminator(G)\n",
    "# 진짜 이미지를 이용해 판별한 값을 구합니다.\n",
    "D_real = discriminator(X)\n",
    "\n",
    "# 논문에 따르면, GAN 모델의 최적화는 loss_G 와 loss_D 를 최대화 하는 것 입니다.\n",
    "# 다만 loss_D와 loss_G는 서로 연관관계가 있기 때문에 두 개의 손실값이 항상 같이 증가하는 경향을 보이지는 않을 것 입니다.\n",
    "# loss_D가 증가하려면 loss_G는 하락해야하고, loss_G가 증가하려면 loss_D는 하락해야하는 경쟁관계에 있기 때문입니다.\n",
    "# 논문의 수식에 따른 다음 로직을 보면 loss_D 를 최대화하기 위해서는 D_gene 값을 최소화하게 됩니다.\n",
    "# 판별기에 진짜 이미지를 넣었을 때에도 최대값을 : tf.log(D_real)\n",
    "# 가짜 이미지를 넣었을 때에도 최대값을 : tf.log(1 - D_gene)\n",
    "# 갖도록 학습시키기 때문입니다.\n",
    "# 이것은 판별기는 생성기가 만들어낸 이미지가 가짜라고 판단하도록 판별기 신경망을 학습시킵니다.\n",
    "loss_D = tf.reduce_mean(tf.log(D_real) + tf.log(1 - D_gene))\n",
    "# 반면 loss_G 를 최대화하기 위해서는 D_gene 값을 최대화하게 되는데,\n",
    "# 이것은 가짜 이미지를 넣었을 때, 판별기가 최대한 실제 이미지라고 판단하도록 생성기 신경망을 학습시킵니다.\n",
    "# 논문에서는 loss_D 와 같은 수식으로 최소화 하는 생성기를 찾지만,\n",
    "# 결국 D_gene 값을 최대화하는 것이므로 다음과 같이 사용할 수 있습니다.\n",
    "loss_G = tf.reduce_mean(tf.log(D_gene))\n",
    "\n",
    "# loss_D 를 구할 때는 판별기 신경망에 사용되는 변수만 사용하고,\n",
    "# loss_G 를 구할 때는 생성기 신경망에 사용되는 변수만 사용하여 최적화를 합니다.\n",
    "D_var_list = [D_W1, D_b1, D_W2, D_b2]\n",
    "G_var_list = [G_W1, G_b1, G_W2, G_b2]\n",
    "\n",
    "# GAN 논문의 수식에 따르면 loss 를 극대화 해야하지만, minimize 하는 최적화 함수를 사용하기 때문에\n",
    "# 최적화 하려는 loss_D 와 loss_G 에 음수 부호를 붙여줍니다.\n",
    "train_D = tf.train.AdamOptimizer(learning_rate).minimize(-loss_D,\n",
    "                                                         var_list=D_var_list)\n",
    "train_G = tf.train.AdamOptimizer(learning_rate).minimize(-loss_G,\n",
    "                                                         var_list=G_var_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dcc2bda8a8e426ab81c909396342c0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0000 \t D loss: -0.4322 \t G loss: -2.089\n",
      "Epoch: 0001 \t D loss: -0.4494 \t G loss: -2.377\n",
      "Epoch: 0002 \t D loss: -0.1497 \t G loss: -3.09\n",
      "Epoch: 0003 \t D loss: -0.4462 \t G loss: -1.813\n",
      "Epoch: 0004 \t D loss: -0.3375 \t G loss: -2.096\n",
      "Epoch: 0005 \t D loss: -0.3034 \t G loss: -2.765\n",
      "Epoch: 0006 \t D loss: -0.2291 \t G loss: -2.553\n",
      "Epoch: 0007 \t D loss: -0.2662 \t G loss: -2.524\n",
      "Epoch: 0008 \t D loss: -0.4001 \t G loss: -2.605\n",
      "Epoch: 0009 \t D loss: -0.3735 \t G loss: -2.396\n",
      "Epoch: 0010 \t D loss: -0.4728 \t G loss: -2.334\n",
      "Epoch: 0011 \t D loss: -0.266 \t G loss: -2.575\n",
      "Epoch: 0012 \t D loss: -0.3999 \t G loss: -2.107\n",
      "Epoch: 0013 \t D loss: -0.3767 \t G loss: -2.439\n",
      "Epoch: 0014 \t D loss: -0.5242 \t G loss: -2.353\n",
      "Epoch: 0015 \t D loss: -0.6394 \t G loss: -2.158\n",
      "Epoch: 0016 \t D loss: -0.4355 \t G loss: -2.305\n",
      "Epoch: 0017 \t D loss: -0.6227 \t G loss: -2.075\n",
      "Epoch: 0018 \t D loss: -0.4069 \t G loss: -2.235\n",
      "Epoch: 0019 \t D loss: -0.4811 \t G loss: -2.368\n",
      "Epoch: 0020 \t D loss: -0.5968 \t G loss: -2.028\n",
      "Epoch: 0021 \t D loss: -0.5688 \t G loss: -2.206\n",
      "Epoch: 0022 \t D loss: -0.3014 \t G loss: -2.589\n",
      "Epoch: 0023 \t D loss: -0.3389 \t G loss: -2.593\n",
      "Epoch: 0024 \t D loss: -0.4145 \t G loss: -2.226\n",
      "Epoch: 0025 \t D loss: -0.5281 \t G loss: -2.215\n",
      "Epoch: 0026 \t D loss: -0.4906 \t G loss: -2.349\n",
      "Epoch: 0027 \t D loss: -0.459 \t G loss: -2.2\n",
      "Epoch: 0028 \t D loss: -0.5597 \t G loss: -2.362\n",
      "Epoch: 0029 \t D loss: -0.5984 \t G loss: -2.254\n",
      "Epoch: 0030 \t D loss: -0.5334 \t G loss: -2.806\n",
      "Epoch: 0031 \t D loss: -0.4813 \t G loss: -2.515\n",
      "Epoch: 0032 \t D loss: -0.322 \t G loss: -2.652\n",
      "Epoch: 0033 \t D loss: -0.4644 \t G loss: -2.31\n",
      "Epoch: 0034 \t D loss: -0.5373 \t G loss: -2.392\n",
      "Epoch: 0035 \t D loss: -0.7215 \t G loss: -1.926\n",
      "Epoch: 0036 \t D loss: -0.5895 \t G loss: -1.941\n",
      "Epoch: 0037 \t D loss: -0.7544 \t G loss: -2.141\n",
      "Epoch: 0038 \t D loss: -0.6285 \t G loss: -2.329\n",
      "Epoch: 0039 \t D loss: -0.6667 \t G loss: -2.042\n",
      "Epoch: 0040 \t D loss: -0.7772 \t G loss: -1.862\n",
      "Epoch: 0041 \t D loss: -0.7434 \t G loss: -2.044\n",
      "Epoch: 0042 \t D loss: -0.6031 \t G loss: -2.286\n",
      "Epoch: 0043 \t D loss: -0.5635 \t G loss: -1.947\n",
      "Epoch: 0044 \t D loss: -0.8653 \t G loss: -1.876\n",
      "Epoch: 0045 \t D loss: -0.8635 \t G loss: -2.053\n",
      "Epoch: 0046 \t D loss: -0.6869 \t G loss: -1.731\n",
      "Epoch: 0047 \t D loss: -0.7066 \t G loss: -1.937\n",
      "Epoch: 0048 \t D loss: -0.7701 \t G loss: -1.86\n",
      "Epoch: 0049 \t D loss: -0.6071 \t G loss: -1.892\n",
      "Epoch: 0050 \t D loss: -0.8692 \t G loss: -1.785\n",
      "Epoch: 0051 \t D loss: -0.7834 \t G loss: -1.807\n",
      "Epoch: 0052 \t D loss: -0.8626 \t G loss: -1.702\n",
      "Epoch: 0053 \t D loss: -0.8311 \t G loss: -1.463\n",
      "Epoch: 0054 \t D loss: -0.8108 \t G loss: -1.744\n",
      "Epoch: 0055 \t D loss: -0.9483 \t G loss: -1.683\n",
      "Epoch: 0056 \t D loss: -0.9466 \t G loss: -1.756\n",
      "Epoch: 0057 \t D loss: -0.8759 \t G loss: -1.648\n",
      "Epoch: 0058 \t D loss: -0.9029 \t G loss: -1.871\n",
      "Epoch: 0059 \t D loss: -0.774 \t G loss: -1.91\n",
      "Epoch: 0060 \t D loss: -0.8343 \t G loss: -1.701\n",
      "Epoch: 0061 \t D loss: -0.9174 \t G loss: -1.496\n",
      "Epoch: 0062 \t D loss: -0.8133 \t G loss: -1.711\n",
      "Epoch: 0063 \t D loss: -0.7971 \t G loss: -1.708\n",
      "Epoch: 0064 \t D loss: -0.9675 \t G loss: -1.599\n",
      "Epoch: 0065 \t D loss: -0.8739 \t G loss: -1.639\n",
      "Epoch: 0066 \t D loss: -0.8447 \t G loss: -1.821\n",
      "Epoch: 0067 \t D loss: -0.7978 \t G loss: -1.825\n",
      "Epoch: 0068 \t D loss: -0.7199 \t G loss: -1.837\n",
      "Epoch: 0069 \t D loss: -0.883 \t G loss: -1.868\n",
      "Epoch: 0070 \t D loss: -0.7765 \t G loss: -1.863\n",
      "Epoch: 0071 \t D loss: -0.911 \t G loss: -1.651\n",
      "Epoch: 0072 \t D loss: -0.9122 \t G loss: -1.725\n",
      "Epoch: 0073 \t D loss: -0.9664 \t G loss: -1.643\n",
      "Epoch: 0074 \t D loss: -0.8717 \t G loss: -1.619\n",
      "Epoch: 0075 \t D loss: -0.8589 \t G loss: -1.534\n",
      "Epoch: 0076 \t D loss: -0.9554 \t G loss: -1.439\n",
      "Epoch: 0077 \t D loss: -0.8583 \t G loss: -1.546\n",
      "Epoch: 0078 \t D loss: -0.9537 \t G loss: -1.482\n",
      "Epoch: 0079 \t D loss: -0.9882 \t G loss: -1.602\n",
      "Epoch: 0080 \t D loss: -0.8528 \t G loss: -1.417\n",
      "Epoch: 0081 \t D loss: -0.9366 \t G loss: -1.901\n",
      "Epoch: 0082 \t D loss: -0.7968 \t G loss: -1.618\n",
      "Epoch: 0083 \t D loss: -0.8431 \t G loss: -1.707\n",
      "Epoch: 0084 \t D loss: -0.8685 \t G loss: -1.709\n",
      "Epoch: 0085 \t D loss: -0.7672 \t G loss: -1.782\n",
      "Epoch: 0086 \t D loss: -0.929 \t G loss: -1.47\n",
      "Epoch: 0087 \t D loss: -0.9028 \t G loss: -1.598\n",
      "Epoch: 0088 \t D loss: -0.8378 \t G loss: -1.9\n",
      "Epoch: 0089 \t D loss: -0.8805 \t G loss: -1.863\n",
      "Epoch: 0090 \t D loss: -0.9547 \t G loss: -1.498\n",
      "Epoch: 0091 \t D loss: -0.9693 \t G loss: -1.641\n",
      "Epoch: 0092 \t D loss: -0.9175 \t G loss: -1.656\n",
      "Epoch: 0093 \t D loss: -0.9225 \t G loss: -1.544\n",
      "Epoch: 0094 \t D loss: -0.7971 \t G loss: -1.621\n",
      "Epoch: 0095 \t D loss: -0.9519 \t G loss: -1.529\n",
      "Epoch: 0096 \t D loss: -0.8008 \t G loss: -1.789\n",
      "Epoch: 0097 \t D loss: -0.9562 \t G loss: -1.572\n",
      "Epoch: 0098 \t D loss: -1.016 \t G loss: -1.367\n",
      "Epoch: 0099 \t D loss: -0.974 \t G loss: -1.491\n",
      "\n",
      "최적화 완료!\n"
     ]
    }
   ],
   "source": [
    "#########\n",
    "# 신경망 모델 학습\n",
    "######\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "total_batch = int(mnist.train.num_examples/batch_size)\n",
    "loss_val_D, loss_val_G = 0, 0\n",
    "\n",
    "for epoch in tqdm_notebook(range(total_epoch)):\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        noise = get_noise(batch_size, n_noise)\n",
    "\n",
    "        # 판별기와 생성기 신경망을 각각 학습시킵니다.\n",
    "        _, loss_val_D = sess.run([train_D, loss_D],\n",
    "                                 feed_dict={X: batch_xs, Z: noise})\n",
    "        _, loss_val_G = sess.run([train_G, loss_G],\n",
    "                                 feed_dict={Z: noise})\n",
    "\n",
    "    print('Epoch:', '%04d' % epoch,\n",
    "          '\\t D loss: {:.4}'.format(loss_val_D),\n",
    "          '\\t G loss: {:.4}'.format(loss_val_G))\n",
    "\n",
    "    #########\n",
    "    # 학습이 되어가는 모습을 보기 위해 주기적으로 이미지를 생성하여 저장\n",
    "    ######\n",
    "    if epoch == 0 or (epoch + 1) % 10 == 0:\n",
    "        sample_size = 10\n",
    "        noise = get_noise(sample_size, n_noise)\n",
    "        samples = sess.run(G, feed_dict={Z: noise})\n",
    "\n",
    "        fig, ax = plt.subplots(1, sample_size, figsize=(sample_size, 1))\n",
    "\n",
    "        for i in range(sample_size):\n",
    "            ax[i].set_axis_off()\n",
    "            ax[i].imshow(np.reshape(samples[i], (28, 28)))\n",
    "\n",
    "        plt.savefig('samples/{}.png'.format(str(epoch).zfill(3)), bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "\n",
    "print('최적화 완료!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAN2.py\n",
    "> GAN 모델 응용\n",
    "- GAN 모델을 이용해 단순히 랜덤한 숫자를 생성하는 아닌,\n",
    "- 원하는 손글씨 숫자를 생성하는 모델을 만들어봅니다.\n",
    "- 이런 방식으로 흑백 사진을 컬러로 만든다든가, 또는 선화를 채색한다든가 하는 응용이 가능합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "# 옵션 설정\n",
    "######\n",
    "total_epoch = 100\n",
    "batch_size = 100\n",
    "n_hidden = 256\n",
    "n_input = 28 * 28\n",
    "n_noise = 128\n",
    "n_class = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "# 신경망 모델 구성\n",
    "######\n",
    "X = tf.placeholder(tf.float32, [None, n_input])\n",
    "# 노이즈와 실제 이미지에, 그에 해당하는 숫자에 대한 정보를 넣어주기 위해 사용합니다.\n",
    "Y = tf.placeholder(tf.float32, [None, n_class])\n",
    "Z = tf.placeholder(tf.float32, [None, n_noise])\n",
    "\n",
    "\n",
    "def generator(noise, labels):\n",
    "    with tf.variable_scope('generator'):\n",
    "        # noise 값에 labels 정보를 추가합니다.\n",
    "        inputs = tf.concat([noise, labels], 1)\n",
    "\n",
    "        # TensorFlow 에서 제공하는 유틸리티 함수를 이용해 신경망을 매우 간단하게 구성할 수 있습니다.\n",
    "        hidden = tf.layers.dense(inputs, n_hidden,\n",
    "                                 activation=tf.nn.relu)\n",
    "        output = tf.layers.dense(hidden, n_input,\n",
    "                                 activation=tf.nn.sigmoid)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def discriminator(inputs, labels, reuse=None):\n",
    "    with tf.variable_scope('discriminator') as scope:\n",
    "        # 노이즈에서 생성한 이미지와 실제 이미지를 판별하는 모델의 변수를 동일하게 하기 위해,\n",
    "        # 이전에 사용되었던 변수를 재사용하도록 합니다.\n",
    "        if reuse:\n",
    "            scope.reuse_variables()\n",
    "\n",
    "        inputs = tf.concat([inputs, labels], 1)\n",
    "\n",
    "        hidden = tf.layers.dense(inputs, n_hidden,\n",
    "                                 activation=tf.nn.relu)\n",
    "        output = tf.layers.dense(hidden, 1,\n",
    "                                 activation=None)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def get_noise(batch_size, n_noise):\n",
    "    return np.random.uniform(-1., 1., size=[batch_size, n_noise])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성 모델과 판별 모델에 Y 즉, labels 정보를 추가하여\n",
    "# labels 정보에 해당하는 이미지를 생성할 수 있도록 유도합니다.\n",
    "G = generator(Z, Y)\n",
    "D_real = discriminator(X, Y)\n",
    "D_gene = discriminator(G, Y, True)\n",
    "\n",
    "# 손실함수는 다음을 참고하여 GAN 논문에 나온 방식과는 약간 다르게 작성하였습니다.\n",
    "# http://bamos.github.io/2016/08/09/deep-completion/\n",
    "# 진짜 이미지를 판별하는 D_real 값은 1에 가깝도록,\n",
    "# 가짜 이미지를 판별하는 D_gene 값은 0에 가깝도록 하는 손실 함수입니다.\n",
    "loss_D_real = tf.reduce_mean(\n",
    "                    tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                        logits=D_real, labels=tf.ones_like(D_real)))\n",
    "loss_D_gene = tf.reduce_mean(\n",
    "                    tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                        logits=D_gene, labels=tf.zeros_like(D_gene)))\n",
    "# loss_D_real 과 loss_D_gene 을 더한 뒤 이 값을 최소화 하도록 최적화합니다.\n",
    "loss_D = loss_D_real + loss_D_gene\n",
    "# 가짜 이미지를 진짜에 가깝게 만들도록 생성망을 학습시키기 위해, D_gene 을 최대한 1에 가깝도록 만드는 손실함수입니다.\n",
    "loss_G = tf.reduce_mean(\n",
    "                    tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                        logits=D_gene, labels=tf.ones_like(D_gene)))\n",
    "\n",
    "# TensorFlow 에서 제공하는 유틸리티 함수를 이용해\n",
    "# discriminator 와 generator scope 에서 사용된 변수들을 쉽게 가져올 수 있습니다.\n",
    "vars_D = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\n",
    "                           scope='discriminator')\n",
    "vars_G = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\n",
    "                           scope='generator')\n",
    "\n",
    "train_D = tf.train.AdamOptimizer().minimize(loss_D,\n",
    "                                            var_list=vars_D)\n",
    "train_G = tf.train.AdamOptimizer().minimize(loss_G,\n",
    "                                            var_list=vars_G)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c71b93a02944183814756a6ec6dde2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0000 \t D loss: 0.01336 \t G loss: 7.198\n",
      "Epoch: 0001 \t D loss: 0.01907 \t G loss: 7.011\n",
      "Epoch: 0002 \t D loss: 0.01708 \t G loss: 7.048\n",
      "Epoch: 0003 \t D loss: 0.01373 \t G loss: 7.165\n",
      "Epoch: 0004 \t D loss: 0.01721 \t G loss: 6.541\n",
      "Epoch: 0005 \t D loss: 0.00813 \t G loss: 7.265\n",
      "Epoch: 0006 \t D loss: 0.02848 \t G loss: 7.275\n",
      "Epoch: 0007 \t D loss: 0.01588 \t G loss: 7.781\n",
      "Epoch: 0008 \t D loss: 0.04058 \t G loss: 6.968\n",
      "Epoch: 0009 \t D loss: 0.1017 \t G loss: 6.167\n",
      "Epoch: 0010 \t D loss: 0.3411 \t G loss: 5.815\n",
      "Epoch: 0011 \t D loss: 0.2809 \t G loss: 4.597\n",
      "Epoch: 0012 \t D loss: 0.2311 \t G loss: 5.002\n",
      "Epoch: 0013 \t D loss: 0.3752 \t G loss: 5.269\n",
      "Epoch: 0014 \t D loss: 0.5323 \t G loss: 4.5\n",
      "Epoch: 0015 \t D loss: 0.4226 \t G loss: 4.281\n",
      "Epoch: 0016 \t D loss: 0.587 \t G loss: 3.668\n",
      "Epoch: 0017 \t D loss: 0.7184 \t G loss: 3.084\n",
      "Epoch: 0018 \t D loss: 0.4318 \t G loss: 3.361\n",
      "Epoch: 0019 \t D loss: 0.6049 \t G loss: 3.412\n",
      "Epoch: 0020 \t D loss: 0.6688 \t G loss: 3.216\n",
      "Epoch: 0021 \t D loss: 0.6814 \t G loss: 2.986\n",
      "Epoch: 0022 \t D loss: 0.5838 \t G loss: 2.736\n",
      "Epoch: 0023 \t D loss: 0.4586 \t G loss: 3.081\n",
      "Epoch: 0024 \t D loss: 0.6808 \t G loss: 2.157\n",
      "Epoch: 0025 \t D loss: 0.7705 \t G loss: 2.351\n",
      "Epoch: 0026 \t D loss: 0.6724 \t G loss: 2.39\n",
      "Epoch: 0027 \t D loss: 0.5442 \t G loss: 2.906\n",
      "Epoch: 0028 \t D loss: 0.7855 \t G loss: 2.153\n",
      "Epoch: 0029 \t D loss: 0.6642 \t G loss: 2.51\n",
      "Epoch: 0030 \t D loss: 0.7241 \t G loss: 1.963\n",
      "Epoch: 0031 \t D loss: 0.5906 \t G loss: 2.695\n",
      "Epoch: 0032 \t D loss: 0.6835 \t G loss: 1.853\n",
      "Epoch: 0033 \t D loss: 0.7062 \t G loss: 2.033\n",
      "Epoch: 0034 \t D loss: 0.651 \t G loss: 2.632\n",
      "Epoch: 0035 \t D loss: 0.6587 \t G loss: 2.142\n",
      "Epoch: 0036 \t D loss: 0.6194 \t G loss: 2.587\n",
      "Epoch: 0037 \t D loss: 0.7293 \t G loss: 2.081\n",
      "Epoch: 0038 \t D loss: 0.5915 \t G loss: 1.983\n",
      "Epoch: 0039 \t D loss: 0.9856 \t G loss: 2.005\n",
      "Epoch: 0040 \t D loss: 0.6522 \t G loss: 2.254\n",
      "Epoch: 0041 \t D loss: 0.7683 \t G loss: 2.145\n",
      "Epoch: 0042 \t D loss: 0.8208 \t G loss: 1.986\n",
      "Epoch: 0043 \t D loss: 0.7425 \t G loss: 2.358\n",
      "Epoch: 0044 \t D loss: 0.6227 \t G loss: 2.353\n",
      "Epoch: 0045 \t D loss: 0.8582 \t G loss: 1.846\n",
      "Epoch: 0046 \t D loss: 0.6715 \t G loss: 2.145\n",
      "Epoch: 0047 \t D loss: 0.9389 \t G loss: 2.404\n",
      "Epoch: 0048 \t D loss: 0.6418 \t G loss: 2.19\n",
      "Epoch: 0049 \t D loss: 0.6579 \t G loss: 2.367\n",
      "Epoch: 0050 \t D loss: 0.5656 \t G loss: 2.287\n",
      "Epoch: 0051 \t D loss: 0.637 \t G loss: 2.75\n",
      "Epoch: 0052 \t D loss: 0.7578 \t G loss: 2.321\n",
      "Epoch: 0053 \t D loss: 0.6438 \t G loss: 2.448\n",
      "Epoch: 0054 \t D loss: 0.6554 \t G loss: 2.257\n",
      "Epoch: 0055 \t D loss: 0.5972 \t G loss: 2.416\n",
      "Epoch: 0056 \t D loss: 0.6087 \t G loss: 2.739\n",
      "Epoch: 0057 \t D loss: 0.6153 \t G loss: 2.395\n",
      "Epoch: 0058 \t D loss: 0.7876 \t G loss: 2.173\n",
      "Epoch: 0059 \t D loss: 0.7668 \t G loss: 2.543\n",
      "Epoch: 0060 \t D loss: 0.596 \t G loss: 2.209\n",
      "Epoch: 0061 \t D loss: 0.6291 \t G loss: 2.342\n",
      "Epoch: 0062 \t D loss: 0.6772 \t G loss: 2.06\n",
      "Epoch: 0063 \t D loss: 0.7208 \t G loss: 2.01\n",
      "Epoch: 0064 \t D loss: 0.6836 \t G loss: 2.534\n",
      "Epoch: 0065 \t D loss: 0.6862 \t G loss: 2.233\n",
      "Epoch: 0066 \t D loss: 0.7755 \t G loss: 2.417\n",
      "Epoch: 0067 \t D loss: 0.6244 \t G loss: 2.542\n",
      "Epoch: 0068 \t D loss: 0.7653 \t G loss: 2.115\n",
      "Epoch: 0069 \t D loss: 0.6878 \t G loss: 2.354\n",
      "Epoch: 0070 \t D loss: 0.6238 \t G loss: 2.431\n",
      "Epoch: 0071 \t D loss: 0.6747 \t G loss: 1.951\n",
      "Epoch: 0072 \t D loss: 0.6875 \t G loss: 2.104\n",
      "Epoch: 0073 \t D loss: 0.6928 \t G loss: 1.787\n",
      "Epoch: 0074 \t D loss: 0.5436 \t G loss: 2.392\n",
      "Epoch: 0075 \t D loss: 0.758 \t G loss: 2.069\n",
      "Epoch: 0076 \t D loss: 0.651 \t G loss: 2.161\n",
      "Epoch: 0077 \t D loss: 0.9445 \t G loss: 2.035\n",
      "Epoch: 0078 \t D loss: 0.776 \t G loss: 2.499\n",
      "Epoch: 0079 \t D loss: 0.7781 \t G loss: 2.356\n",
      "Epoch: 0080 \t D loss: 0.743 \t G loss: 2.157\n",
      "Epoch: 0081 \t D loss: 0.775 \t G loss: 2.095\n",
      "Epoch: 0082 \t D loss: 0.7645 \t G loss: 1.936\n",
      "Epoch: 0083 \t D loss: 0.6725 \t G loss: 2.365\n",
      "Epoch: 0084 \t D loss: 0.8644 \t G loss: 1.799\n",
      "Epoch: 0085 \t D loss: 0.6931 \t G loss: 1.879\n",
      "Epoch: 0086 \t D loss: 0.692 \t G loss: 2.097\n",
      "Epoch: 0087 \t D loss: 0.6883 \t G loss: 2.295\n",
      "Epoch: 0088 \t D loss: 0.6362 \t G loss: 1.942\n",
      "Epoch: 0089 \t D loss: 0.8042 \t G loss: 2.425\n",
      "Epoch: 0090 \t D loss: 0.7506 \t G loss: 2.058\n",
      "Epoch: 0091 \t D loss: 0.7478 \t G loss: 2.189\n",
      "Epoch: 0092 \t D loss: 0.7039 \t G loss: 2.207\n",
      "Epoch: 0093 \t D loss: 0.6396 \t G loss: 2.397\n",
      "Epoch: 0094 \t D loss: 0.7168 \t G loss: 1.863\n",
      "Epoch: 0095 \t D loss: 0.5672 \t G loss: 2.596\n",
      "Epoch: 0096 \t D loss: 0.699 \t G loss: 2.175\n",
      "Epoch: 0097 \t D loss: 0.6424 \t G loss: 2.252\n",
      "Epoch: 0098 \t D loss: 0.6039 \t G loss: 1.691\n",
      "Epoch: 0099 \t D loss: 0.6666 \t G loss: 2.398\n",
      "\n",
      "최적화 완료!\n"
     ]
    }
   ],
   "source": [
    "#########\n",
    "# 신경망 모델 학습\n",
    "######\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "total_batch = int(mnist.train.num_examples/batch_size)\n",
    "loss_val_D, loss_val_G = 0, 0\n",
    "\n",
    "for epoch in tqdm_notebook(range(total_epoch)):\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        noise = get_noise(batch_size, n_noise)\n",
    "\n",
    "        _, loss_val_D = sess.run([train_D, loss_D],\n",
    "                                 feed_dict={X: batch_xs, Y: batch_ys, Z: noise})\n",
    "        _, loss_val_G = sess.run([train_G, loss_G],\n",
    "                                 feed_dict={Y: batch_ys, Z: noise})\n",
    "\n",
    "    print('Epoch:', '%04d' % epoch,\n",
    "          '\\t D loss: {:.4}'.format(loss_val_D),\n",
    "          '\\t G loss: {:.4}'.format(loss_val_G))\n",
    "\n",
    "    #########\n",
    "    # 학습이 되어가는 모습을 보기 위해 주기적으로 레이블에 따른 이미지를 생성하여 저장\n",
    "    ######\n",
    "    if epoch == 0 or (epoch + 1) % 10 == 0:\n",
    "        sample_size = 10\n",
    "        noise = get_noise(sample_size, n_noise)\n",
    "        samples = sess.run(G,\n",
    "                           feed_dict={Y: mnist.test.labels[:sample_size],\n",
    "                                      Z: noise})\n",
    "\n",
    "        fig, ax = plt.subplots(2, sample_size, figsize=(sample_size, 2))\n",
    "\n",
    "        for i in range(sample_size):\n",
    "            ax[0][i].set_axis_off()\n",
    "            ax[1][i].set_axis_off()\n",
    "\n",
    "            ax[0][i].imshow(np.reshape(mnist.test.images[i], (28, 28)))\n",
    "            ax[1][i].imshow(np.reshape(samples[i], (28, 28)))\n",
    "\n",
    "        plt.savefig('samples2/{}.png'.format(str(epoch).zfill(3)), bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "\n",
    "print('최적화 완료!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01 - GAN.py   02 - GAN2.py\r\n"
     ]
    }
   ],
   "source": [
    "% ls 09\\ -\\ GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 2016년에 가장 관심을 많이 받았던 비감독(Unsupervised) 학습 방법인\n",
      "# Generative Adversarial Network(GAN)을 구현해봅니다.\n",
      "# https://arxiv.org/abs/1406.2661\n",
      "import tensorflow as tf\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "\n",
      "from tensorflow.examples.tutorials.mnist import input_data\n",
      "mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)\n",
      "\n",
      "#########\n",
      "# 옵션 설정\n",
      "######\n",
      "total_epoch = 100\n",
      "batch_size = 100\n",
      "learning_rate = 0.0002\n",
      "# 신경망 레이어 구성 옵션\n",
      "n_hidden = 256\n",
      "n_input = 28 * 28\n",
      "n_noise = 128  # 생성기의 입력값으로 사용할 노이즈의 크기\n",
      "\n",
      "#########\n",
      "# 신경망 모델 구성\n",
      "######\n",
      "# GAN 도 Unsupervised 학습이므로 Autoencoder 처럼 Y 를 사용하지 않습니다.\n",
      "X = tf.placeholder(tf.float32, [None, n_input])\n",
      "# 노이즈 Z를 입력값으로 사용합니다.\n",
      "Z = tf.placeholder(tf.float32, [None, n_noise])\n",
      "\n",
      "# 생성기 신경망에 사용하는 변수들입니다.\n",
      "G_W1 = tf.Variable(tf.random_normal([n_noise, n_hidden], stddev=0.01))\n",
      "G_b1 = tf.Variable(tf.zeros([n_hidden]))\n",
      "G_W2 = tf.Variable(tf.random_normal([n_hidden, n_input], stddev=0.01))\n",
      "G_b2 = tf.Variable(tf.zeros([n_input]))\n",
      "\n",
      "# 판별기 신경망에 사용하는 변수들입니다.\n",
      "D_W1 = tf.Variable(tf.random_normal([n_input, n_hidden], stddev=0.01))\n",
      "D_b1 = tf.Variable(tf.zeros([n_hidden]))\n",
      "# 판별기의 최종 결과값은 얼마나 진짜와 가깝냐를 판단하는 한 개의 스칼라값입니다.\n",
      "D_W2 = tf.Variable(tf.random_normal([n_hidden, 1], stddev=0.01))\n",
      "D_b2 = tf.Variable(tf.zeros([1]))\n",
      "\n",
      "\n",
      "# 생성기(G) 신경망을 구성합니다.\n",
      "def generator(noise_z):\n",
      "    hidden = tf.nn.relu(\n",
      "                    tf.matmul(noise_z, G_W1) + G_b1)\n",
      "    output = tf.nn.sigmoid(\n",
      "                    tf.matmul(hidden, G_W2) + G_b2)\n",
      "\n",
      "    return output\n",
      "\n",
      "\n",
      "# 판별기(D) 신경망을 구성합니다.\n",
      "def discriminator(inputs):\n",
      "    hidden = tf.nn.relu(\n",
      "                    tf.matmul(inputs, D_W1) + D_b1)\n",
      "    output = tf.nn.sigmoid(\n",
      "                    tf.matmul(hidden, D_W2) + D_b2)\n",
      "\n",
      "    return output\n",
      "\n",
      "\n",
      "# 랜덤한 노이즈(Z)를 만듭니다.\n",
      "def get_noise(batch_size, n_noise):\n",
      "    return np.random.normal(size=(batch_size, n_noise))\n",
      "\n",
      "\n",
      "# 노이즈를 이용해 랜덤한 이미지를 생성합니다.\n",
      "G = generator(Z)\n",
      "# 노이즈를 이용해 생성한 이미지가 진짜 이미지인지 판별한 값을 구합니다.\n",
      "D_gene = discriminator(G)\n",
      "# 진짜 이미지를 이용해 판별한 값을 구합니다.\n",
      "D_real = discriminator(X)\n",
      "\n",
      "# 논문에 따르면, GAN 모델의 최적화는 loss_G 와 loss_D 를 최대화 하는 것 입니다.\n",
      "# 다만 loss_D와 loss_G는 서로 연관관계가 있기 때문에 두 개의 손실값이 항상 같이 증가하는 경향을 보이지는 않을 것 입니다.\n",
      "# loss_D가 증가하려면 loss_G는 하락해야하고, loss_G가 증가하려면 loss_D는 하락해야하는 경쟁관계에 있기 때문입니다.\n",
      "# 논문의 수식에 따른 다음 로직을 보면 loss_D 를 최대화하기 위해서는 D_gene 값을 최소화하게 됩니다.\n",
      "# 판별기에 진짜 이미지를 넣었을 때에도 최대값을 : tf.log(D_real)\n",
      "# 가짜 이미지를 넣었을 때에도 최대값을 : tf.log(1 - D_gene)\n",
      "# 갖도록 학습시키기 때문입니다.\n",
      "# 이것은 판별기는 생성기가 만들어낸 이미지가 가짜라고 판단하도록 판별기 신경망을 학습시킵니다.\n",
      "loss_D = tf.reduce_mean(tf.log(D_real) + tf.log(1 - D_gene))\n",
      "# 반면 loss_G 를 최대화하기 위해서는 D_gene 값을 최대화하게 되는데,\n",
      "# 이것은 가짜 이미지를 넣었을 때, 판별기가 최대한 실제 이미지라고 판단하도록 생성기 신경망을 학습시킵니다.\n",
      "# 논문에서는 loss_D 와 같은 수식으로 최소화 하는 생성기를 찾지만,\n",
      "# 결국 D_gene 값을 최대화하는 것이므로 다음과 같이 사용할 수 있습니다.\n",
      "loss_G = tf.reduce_mean(tf.log(D_gene))\n",
      "\n",
      "# loss_D 를 구할 때는 판별기 신경망에 사용되는 변수만 사용하고,\n",
      "# loss_G 를 구할 때는 생성기 신경망에 사용되는 변수만 사용하여 최적화를 합니다.\n",
      "D_var_list = [D_W1, D_b1, D_W2, D_b2]\n",
      "G_var_list = [G_W1, G_b1, G_W2, G_b2]\n",
      "\n",
      "# GAN 논문의 수식에 따르면 loss 를 극대화 해야하지만, minimize 하는 최적화 함수를 사용하기 때문에\n",
      "# 최적화 하려는 loss_D 와 loss_G 에 음수 부호를 붙여줍니다.\n",
      "train_D = tf.train.AdamOptimizer(learning_rate).minimize(-loss_D,\n",
      "                                                         var_list=D_var_list)\n",
      "train_G = tf.train.AdamOptimizer(learning_rate).minimize(-loss_G,\n",
      "                                                         var_list=G_var_list)\n",
      "\n",
      "#########\n",
      "# 신경망 모델 학습\n",
      "######\n",
      "sess = tf.Session()\n",
      "sess.run(tf.global_variables_initializer())\n",
      "\n",
      "total_batch = int(mnist.train.num_examples/batch_size)\n",
      "loss_val_D, loss_val_G = 0, 0\n",
      "\n",
      "for epoch in range(total_epoch):\n",
      "    for i in range(total_batch):\n",
      "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
      "        noise = get_noise(batch_size, n_noise)\n",
      "\n",
      "        # 판별기와 생성기 신경망을 각각 학습시킵니다.\n",
      "        _, loss_val_D = sess.run([train_D, loss_D],\n",
      "                                 feed_dict={X: batch_xs, Z: noise})\n",
      "        _, loss_val_G = sess.run([train_G, loss_G],\n",
      "                                 feed_dict={Z: noise})\n",
      "\n",
      "    print('Epoch:', '%04d' % epoch,\n",
      "          'D loss: {:.4}'.format(loss_val_D),\n",
      "          'G loss: {:.4}'.format(loss_val_G))\n",
      "\n",
      "    #########\n",
      "    # 학습이 되어가는 모습을 보기 위해 주기적으로 이미지를 생성하여 저장\n",
      "    ######\n",
      "    if epoch == 0 or (epoch + 1) % 10 == 0:\n",
      "        sample_size = 10\n",
      "        noise = get_noise(sample_size, n_noise)\n",
      "        samples = sess.run(G, feed_dict={Z: noise})\n",
      "\n",
      "        fig, ax = plt.subplots(1, sample_size, figsize=(sample_size, 1))\n",
      "\n",
      "        for i in range(sample_size):\n",
      "            ax[i].set_axis_off()\n",
      "            ax[i].imshow(np.reshape(samples[i], (28, 28)))\n",
      "\n",
      "        plt.savefig('samples/{}.png'.format(str(epoch).zfill(3)), bbox_inches='tight')\n",
      "        plt.close(fig)\n",
      "\n",
      "print('최적화 완료!')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "src_file = '09 - GAN/01 - GAN.py'\n",
    "# src_file = '09 - GAN/02 - GAN2.py'\n",
    "\n",
    "with open(src_file, 'r') as fp:\n",
    "    code = fp.read()\n",
    "\n",
    "print(code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf9-1_GAN.py \n",
    "<hr>\n",
    "``` python\n",
    "# 2016년에 가장 관심을 많이 받았던 비감독(Unsupervised) 학습 방법인\n",
    "# Generative Adversarial Network(GAN)을 구현해봅니다.\n",
    "# https://arxiv.org/abs/1406.2661\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)\n",
    "\n",
    "#########\n",
    "# 옵션 설정\n",
    "######\n",
    "total_epoch = 100\n",
    "batch_size = 100\n",
    "learning_rate = 0.0002\n",
    "# 신경망 레이어 구성 옵션\n",
    "n_hidden = 256\n",
    "n_input = 28 * 28\n",
    "n_noise = 128  # 생성기의 입력값으로 사용할 노이즈의 크기\n",
    "\n",
    "#########\n",
    "# 신경망 모델 구성\n",
    "######\n",
    "# GAN 도 Unsupervised 학습이므로 Autoencoder 처럼 Y 를 사용하지 않습니다.\n",
    "X = tf.placeholder(tf.float32, [None, n_input])\n",
    "# 노이즈 Z를 입력값으로 사용합니다.\n",
    "Z = tf.placeholder(tf.float32, [None, n_noise])\n",
    "\n",
    "# 생성기 신경망에 사용하는 변수들입니다.\n",
    "G_W1 = tf.Variable(tf.random_normal([n_noise, n_hidden], stddev=0.01))\n",
    "G_b1 = tf.Variable(tf.zeros([n_hidden]))\n",
    "G_W2 = tf.Variable(tf.random_normal([n_hidden, n_input], stddev=0.01))\n",
    "G_b2 = tf.Variable(tf.zeros([n_input]))\n",
    "\n",
    "# 판별기 신경망에 사용하는 변수들입니다.\n",
    "D_W1 = tf.Variable(tf.random_normal([n_input, n_hidden], stddev=0.01))\n",
    "D_b1 = tf.Variable(tf.zeros([n_hidden]))\n",
    "# 판별기의 최종 결과값은 얼마나 진짜와 가깝냐를 판단하는 한 개의 스칼라값입니다.\n",
    "D_W2 = tf.Variable(tf.random_normal([n_hidden, 1], stddev=0.01))\n",
    "D_b2 = tf.Variable(tf.zeros([1]))\n",
    "\n",
    "\n",
    "# 생성기(G) 신경망을 구성합니다.\n",
    "def generator(noise_z):\n",
    "    hidden = tf.nn.relu(\n",
    "                    tf.matmul(noise_z, G_W1) + G_b1)\n",
    "    output = tf.nn.sigmoid(\n",
    "                    tf.matmul(hidden, G_W2) + G_b2)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "# 판별기(D) 신경망을 구성합니다.\n",
    "def discriminator(inputs):\n",
    "    hidden = tf.nn.relu(\n",
    "                    tf.matmul(inputs, D_W1) + D_b1)\n",
    "    output = tf.nn.sigmoid(\n",
    "                    tf.matmul(hidden, D_W2) + D_b2)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "# 랜덤한 노이즈(Z)를 만듭니다.\n",
    "def get_noise(batch_size, n_noise):\n",
    "    return np.random.normal(size=(batch_size, n_noise))\n",
    "\n",
    "\n",
    "# 노이즈를 이용해 랜덤한 이미지를 생성합니다.\n",
    "G = generator(Z)\n",
    "# 노이즈를 이용해 생성한 이미지가 진짜 이미지인지 판별한 값을 구합니다.\n",
    "D_gene = discriminator(G)\n",
    "# 진짜 이미지를 이용해 판별한 값을 구합니다.\n",
    "D_real = discriminator(X)\n",
    "\n",
    "# 논문에 따르면, GAN 모델의 최적화는 loss_G 와 loss_D 를 최대화 하는 것 입니다.\n",
    "# 다만 loss_D와 loss_G는 서로 연관관계가 있기 때문에 두 개의 손실값이 항상 같이 증가하는 경향을 보이지는 않을 것 입니다.\n",
    "# loss_D가 증가하려면 loss_G는 하락해야하고, loss_G가 증가하려면 loss_D는 하락해야하는 경쟁관계에 있기 때문입니다.\n",
    "# 논문의 수식에 따른 다음 로직을 보면 loss_D 를 최대화하기 위해서는 D_gene 값을 최소화하게 됩니다.\n",
    "# 판별기에 진짜 이미지를 넣었을 때에도 최대값을 : tf.log(D_real)\n",
    "# 가짜 이미지를 넣었을 때에도 최대값을 : tf.log(1 - D_gene)\n",
    "# 갖도록 학습시키기 때문입니다.\n",
    "# 이것은 판별기는 생성기가 만들어낸 이미지가 가짜라고 판단하도록 판별기 신경망을 학습시킵니다.\n",
    "loss_D = tf.reduce_mean(tf.log(D_real) + tf.log(1 - D_gene))\n",
    "# 반면 loss_G 를 최대화하기 위해서는 D_gene 값을 최대화하게 되는데,\n",
    "# 이것은 가짜 이미지를 넣었을 때, 판별기가 최대한 실제 이미지라고 판단하도록 생성기 신경망을 학습시킵니다.\n",
    "# 논문에서는 loss_D 와 같은 수식으로 최소화 하는 생성기를 찾지만,\n",
    "# 결국 D_gene 값을 최대화하는 것이므로 다음과 같이 사용할 수 있습니다.\n",
    "loss_G = tf.reduce_mean(tf.log(D_gene))\n",
    "\n",
    "# loss_D 를 구할 때는 판별기 신경망에 사용되는 변수만 사용하고,\n",
    "# loss_G 를 구할 때는 생성기 신경망에 사용되는 변수만 사용하여 최적화를 합니다.\n",
    "D_var_list = [D_W1, D_b1, D_W2, D_b2]\n",
    "G_var_list = [G_W1, G_b1, G_W2, G_b2]\n",
    "\n",
    "# GAN 논문의 수식에 따르면 loss 를 극대화 해야하지만, minimize 하는 최적화 함수를 사용하기 때문에\n",
    "# 최적화 하려는 loss_D 와 loss_G 에 음수 부호를 붙여줍니다.\n",
    "train_D = tf.train.AdamOptimizer(learning_rate).minimize(-loss_D,\n",
    "                                                         var_list=D_var_list)\n",
    "train_G = tf.train.AdamOptimizer(learning_rate).minimize(-loss_G,\n",
    "                                                         var_list=G_var_list)\n",
    "\n",
    "#########\n",
    "# 신경망 모델 학습\n",
    "######\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "total_batch = int(mnist.train.num_examples/batch_size)\n",
    "loss_val_D, loss_val_G = 0, 0\n",
    "\n",
    "for epoch in range(total_epoch):\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        noise = get_noise(batch_size, n_noise)\n",
    "\n",
    "        # 판별기와 생성기 신경망을 각각 학습시킵니다.\n",
    "        _, loss_val_D = sess.run([train_D, loss_D],\n",
    "                                 feed_dict={X: batch_xs, Z: noise})\n",
    "        _, loss_val_G = sess.run([train_G, loss_G],\n",
    "                                 feed_dict={Z: noise})\n",
    "\n",
    "    print('Epoch:', '%04d' % epoch,\n",
    "          'D loss: {:.4}'.format(loss_val_D),\n",
    "          'G loss: {:.4}'.format(loss_val_G))\n",
    "\n",
    "    #########\n",
    "    # 학습이 되어가는 모습을 보기 위해 주기적으로 이미지를 생성하여 저장\n",
    "    ######\n",
    "    if epoch == 0 or (epoch + 1) % 10 == 0:\n",
    "        sample_size = 10\n",
    "        noise = get_noise(sample_size, n_noise)\n",
    "        samples = sess.run(G, feed_dict={Z: noise})\n",
    "\n",
    "        fig, ax = plt.subplots(1, sample_size, figsize=(sample_size, 1))\n",
    "\n",
    "        for i in range(sample_size):\n",
    "            ax[i].set_axis_off()\n",
    "            ax[i].imshow(np.reshape(samples[i], (28, 28)))\n",
    "\n",
    "        plt.savefig('samples/{}.png'.format(str(epoch).zfill(3)), bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "\n",
    "print('최적화 완료!')\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf9-2_GAN2.py \n",
    "<hr>\n",
    "``` python\n",
    "# GAN 모델을 이용해 단순히 랜덤한 숫자를 생성하는 아닌,\n",
    "# 원하는 손글씨 숫자를 생성하는 모델을 만들어봅니다.\n",
    "# 이런 방식으로 흑백 사진을 컬러로 만든다든가, 또는 선화를 채색한다든가 하는 응용이 가능합니다.\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)\n",
    "\n",
    "#########\n",
    "# 옵션 설정\n",
    "######\n",
    "total_epoch = 100\n",
    "batch_size = 100\n",
    "n_hidden = 256\n",
    "n_input = 28 * 28\n",
    "n_noise = 128\n",
    "n_class = 10\n",
    "\n",
    "#########\n",
    "# 신경망 모델 구성\n",
    "######\n",
    "X = tf.placeholder(tf.float32, [None, n_input])\n",
    "# 노이즈와 실제 이미지에, 그에 해당하는 숫자에 대한 정보를 넣어주기 위해 사용합니다.\n",
    "Y = tf.placeholder(tf.float32, [None, n_class])\n",
    "Z = tf.placeholder(tf.float32, [None, n_noise])\n",
    "\n",
    "\n",
    "def generator(noise, labels):\n",
    "    with tf.variable_scope('generator'):\n",
    "        # noise 값에 labels 정보를 추가합니다.\n",
    "        inputs = tf.concat([noise, labels], 1)\n",
    "\n",
    "        # TensorFlow 에서 제공하는 유틸리티 함수를 이용해 신경망을 매우 간단하게 구성할 수 있습니다.\n",
    "        hidden = tf.layers.dense(inputs, n_hidden,\n",
    "                                 activation=tf.nn.relu)\n",
    "        output = tf.layers.dense(hidden, n_input,\n",
    "                                 activation=tf.nn.sigmoid)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def discriminator(inputs, labels, reuse=None):\n",
    "    with tf.variable_scope('discriminator') as scope:\n",
    "        # 노이즈에서 생성한 이미지와 실제 이미지를 판별하는 모델의 변수를 동일하게 하기 위해,\n",
    "        # 이전에 사용되었던 변수를 재사용하도록 합니다.\n",
    "        if reuse:\n",
    "            scope.reuse_variables()\n",
    "\n",
    "        inputs = tf.concat([inputs, labels], 1)\n",
    "\n",
    "        hidden = tf.layers.dense(inputs, n_hidden,\n",
    "                                 activation=tf.nn.relu)\n",
    "        output = tf.layers.dense(hidden, 1,\n",
    "                                 activation=None)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def get_noise(batch_size, n_noise):\n",
    "    return np.random.uniform(-1., 1., size=[batch_size, n_noise])\n",
    "\n",
    "# 생성 모델과 판별 모델에 Y 즉, labels 정보를 추가하여\n",
    "# labels 정보에 해당하는 이미지를 생성할 수 있도록 유도합니다.\n",
    "G = generator(Z, Y)\n",
    "D_real = discriminator(X, Y)\n",
    "D_gene = discriminator(G, Y, True)\n",
    "\n",
    "# 손실함수는 다음을 참고하여 GAN 논문에 나온 방식과는 약간 다르게 작성하였습니다.\n",
    "# http://bamos.github.io/2016/08/09/deep-completion/\n",
    "# 진짜 이미지를 판별하는 D_real 값은 1에 가깝도록,\n",
    "# 가짜 이미지를 판별하는 D_gene 값은 0에 가깝도록 하는 손실 함수입니다.\n",
    "loss_D_real = tf.reduce_mean(\n",
    "                    tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                        logits=D_real, labels=tf.ones_like(D_real)))\n",
    "loss_D_gene = tf.reduce_mean(\n",
    "                    tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                        logits=D_gene, labels=tf.zeros_like(D_gene)))\n",
    "# loss_D_real 과 loss_D_gene 을 더한 뒤 이 값을 최소화 하도록 최적화합니다.\n",
    "loss_D = loss_D_real + loss_D_gene\n",
    "# 가짜 이미지를 진짜에 가깝게 만들도록 생성망을 학습시키기 위해, D_gene 을 최대한 1에 가깝도록 만드는 손실함수입니다.\n",
    "loss_G = tf.reduce_mean(\n",
    "                    tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                        logits=D_gene, labels=tf.ones_like(D_gene)))\n",
    "\n",
    "# TensorFlow 에서 제공하는 유틸리티 함수를 이용해\n",
    "# discriminator 와 generator scope 에서 사용된 변수들을 쉽게 가져올 수 있습니다.\n",
    "vars_D = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\n",
    "                           scope='discriminator')\n",
    "vars_G = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\n",
    "                           scope='generator')\n",
    "\n",
    "train_D = tf.train.AdamOptimizer().minimize(loss_D,\n",
    "                                            var_list=vars_D)\n",
    "train_G = tf.train.AdamOptimizer().minimize(loss_G,\n",
    "                                            var_list=vars_G)\n",
    "\n",
    "#########\n",
    "# 신경망 모델 학습\n",
    "######\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "total_batch = int(mnist.train.num_examples/batch_size)\n",
    "loss_val_D, loss_val_G = 0, 0\n",
    "\n",
    "for epoch in range(total_epoch):\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        noise = get_noise(batch_size, n_noise)\n",
    "\n",
    "        _, loss_val_D = sess.run([train_D, loss_D],\n",
    "                                 feed_dict={X: batch_xs, Y: batch_ys, Z: noise})\n",
    "        _, loss_val_G = sess.run([train_G, loss_G],\n",
    "                                 feed_dict={Y: batch_ys, Z: noise})\n",
    "\n",
    "    print('Epoch:', '%04d' % epoch,\n",
    "          'D loss: {:.4}'.format(loss_val_D),\n",
    "          'G loss: {:.4}'.format(loss_val_G))\n",
    "\n",
    "    #########\n",
    "    # 학습이 되어가는 모습을 보기 위해 주기적으로 레이블에 따른 이미지를 생성하여 저장\n",
    "    ######\n",
    "    if epoch == 0 or (epoch + 1) % 10 == 0:\n",
    "        sample_size = 10\n",
    "        noise = get_noise(sample_size, n_noise)\n",
    "        samples = sess.run(G,\n",
    "                           feed_dict={Y: mnist.test.labels[:sample_size],\n",
    "                                      Z: noise})\n",
    "\n",
    "        fig, ax = plt.subplots(2, sample_size, figsize=(sample_size, 2))\n",
    "\n",
    "        for i in range(sample_size):\n",
    "            ax[0][i].set_axis_off()\n",
    "            ax[1][i].set_axis_off()\n",
    "\n",
    "            ax[0][i].imshow(np.reshape(mnist.test.images[i], (28, 28)))\n",
    "            ax[1][i].imshow(np.reshape(samples[i], (28, 28)))\n",
    "\n",
    "        plt.savefig('samples2/{}.png'.format(str(epoch).zfill(3)), bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "\n",
    "print('최적화 완료!')\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
